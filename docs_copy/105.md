




### 任务简述


* 这是文本标签化系统的最后一步，完成各个模块的集成以及API的测试是工作中的重要里程碑，在这个过程中，我们将学习使用多进程训练以及多线程预测技术，至此将得到一个完整的文本标签化系统，它能够对文本进行打标签的工作。



### 任务目的

* 对标签模型进行分布式训练，与之对应的服务进行并行部署，并集成文本标签化系统的各个模块，使得服务正常对外提供API。


### 任务步骤
	
* Step1: 多模型多进程训练
* Step2: 多模型多线程预测
* Step3: 系统联调与测试

---





#### Step1: 多模型多进程训练

* 当前步骤简述：
	* 随着标签体系越来越大，模型循环训练所需要的时间也越来越长，为了更好的利用服务器资源，我们在这一步进行模型的分布式训练，首先会有实现一些资源监控（CPU，内存）的逻辑，进行根据资源的占用情况，合理地开启多进程（分布式）进行训练。


* 使用多进程的原因：
	* 在python这门语言中，存在一个全局解释锁，它使系统的多个线程无法一同使用CPU资源，对于计算密集型任务，必须采用多进程方式并行化，而我们的模型训练，正是最典型的计算密集型任务，里面涵盖大量的矩阵计算，因此，我们这里使用多进程训练。


* CPU/内存正常负载值：
	* 是指我们的CPU/内存正常工作时占用率，比这个值小，说明我们的CPU/内存工作很轻松，比这个值大，说明工作起来已经很劳累了，一般取CPU/内存占用率的55%。


* CPU/内存危险负载值:
	* 是指我们的CPU/内存危险工作时的占用率，比这值小，系统不会挂掉或者开启自动保护。比这个值大，系统可能随时会挂掉或开启自动保护。一般取CPU/内存占用率的95%。 

* 多模型多进程的训练逻辑:
	* 开启第一个模型训练进程，进入训练状态后开始检测占用资源是否小于CPU/内存正常负载值。小于CPU/内存正常负载值，则开启第二个模型训练任务。否则，开始检测占用资源是否大于CPU/内存危险负载值，如果大于，则kill掉这个进程，否则，说明占用率处在正常负载值与危险负载值之间，此时，等待该模型训练进程结束，再自动开启下一个模型训练进程。


* 代码实现位置：
	* 不存在的路径需要自己的创建
	* /data/labeled_project/text_labeled/model_train/multiprocess_train.py


#### 让我们动手做起来吧！


* 代码实现：

```python
import time

# 用于开启多个进程
import subprocess

# 使用psutil进行资源监控，主要获取cpu与内存占用情况。
import psutil

# 设定CPU与内存的正常和危险占用阈值
CPU_NOR_LIMIT = MEM_NOR_LIMIT = 55
CPU_DAN_LIMIT = MEM_DAN_LIMIT = 95

# 模型训练脚本列表
model_train_list = ["python movie_model_train.py", "python beauty_model_train.py"]

# 创建subp的列表容器，用于装载子进程
subp = []

def detect_cpu_mem(): 
    """检测CPU和内存占用率"""
    print("进行mem和cpu检测:")
    # 内存检测
    mem = psutil.virtual_memory().percent
    # psutil检测cpu时间隔至少3s以上
    cpu = psutil.cpu_percent(3)
    print("当前内存占用率:" + str(mem) + "%")
    print("当前CPU占用率:" + str(cpu) + "%")
    return  mem, cpu


def single_model_train(model):
    """开启单个模型的训练"""
    p = subprocess.Popen(model, shell=True)
    # 等待3秒预估模型进入训练状态，即资源占用趋于稳定。
    time.sleep(3)
    # 进行资源检测
    mem, cpu = detect_cpu_mem()

    # 内存和CPU同时小于正常负载值，则任其继续运行，并装入列表
    if mem < MEM_NOR_LIMIT and cpu < CPU_NOR_LIMIT:
        subp.append(p)
        print("该模型进入正常训练过程，并可以开启下一模型训练！")
    else:
        # 判断是否大于危险负载值，若大于，将kill该进程，
        # 否则等待该进程结束，再进行其他训练任务。
        if mem > MEM_DAN_LIMIT or cpu > CPU_DAN_LIMIT:
            p.kill()
            print("该模型没有进入正常训练过程！")
        else:
            p.wait()
            print("该模型进入正常训练过程, 但不要开启下一个模型训练!")


def start_multiprocess_train():
    """开启多进程训练"""
    print("启动多模型训练：")

    # 遍历启动模型的命令，准备循环开启训练进程
    for i, model in enumerate(model_train_list):
        print("__________________________")
        print("正在启动第" + str(i+1) + "个模型：")
        # 启动模型训练
        single_model_train(model)
    else:
        # 所有装入列表的进程都会等待其自然结束后才会停止该函数所在的进程
        print("正在等待所有模型训练结束!")
        list(map(lambda x: x.wait(), subp))
        print("完成!")
```



> * 运行示例：

```python
start_multiprocess_train()
```


```text
# 检测内存和cpu占用率, 并打印脚本文件movie_model_train.py的执行内容.
当前内存占用率:7.5%
当前CPU占用率:25.1%
该模型进入正常训练过程, 并可以开启下一模型训练!

Epoch 3/20
5299/5299 [==============================] - 6s 1ms/step - loss: 0.4098 - acc: 0.7996 - val_loss: 1.0321 - val_acc: 0.1647
Epoch 4/20
5299/5299 [==============================] - 7s 1ms/step - loss: 0.3190 - acc: 0.8517 - val_loss: 0.8503 - val_acc: 0.3124
Epoch 5/20
5299/5299 [==============================] - 6s 1ms/step - loss: 0.2384 - acc: 0.9109 - val_loss: 0.6873 - val_acc: 0.5025
Epoch 6/20
5299/5299 [==============================] - 6s 1ms/step - loss: 0.1781 - acc: 0.9504 - val_loss: 0.6238 - val_acc: 0.5756
Epoch 7/20
5299/5299 [==============================] - 6s 1ms/step - loss: 0.1359 - acc: 0.9711 - val_loss: 0.5465 - val_acc: 0.6401
```

* 当前步骤总结：
	* 这样我们通过一系列函数构建了多模型的多进程训练逻辑，这一步骤中只是添加了两个脚本文件，同学们还可以在自己的服务器上尝试更多的模型。


---


#### Step2: 多模型多线程预测

* 当前步骤简述：
	* 在工业生产中，模型的训练是离线的，而预测服务往往是在线的；当前步骤的内容和Step1没有先后顺序，但在当前步骤中实现的多线程预测函数是主服务中重要的一环，我们在[任务一Step4: 匹配歧义判断]时假设的函数将在这里进行完善。

* 进行多线程预测的原因：
	* 根据我们的业务特点，用户的每次请求，都有可能调用多个模型进行预测，而串行预测的方式，远远不能满足预测的性能要求. 这就需要预测过程必须能够并行化，并很容易的整合全部的结果.


* 模型预测过程也是计算密集型, 为什么没有受到全局解释锁的影响:
	* 虽然预测过程也是计算密集型的，但是我们对这个计算过程进行了封装, 使它是在模型微服务中进行, 而我们线程只是负责调用服务并整合结果而已, 因此不会受到全局解释锁的影响.


* 相关前提：
	* 完成了多个标签的模型子服务部署


* 代码实现位置：
	* /data/labeled_project/text_labeled/model_train/multithread_predict.py



#### 让我们动手做起来吧！


* 代码实现：

```python
# 导入必备的工具包
import json
import threading
import requests
from sklearn.externals import joblib

# 定义模型配置路径，它指向一个json文件
model_config_path = "/data/labeled_project/text_labeled/model_train/model_config.json"
model_prediction = []

# 将持久化的模型配置文件加载到内存
model_config = json.load(open(model_config_path, "r"))


def pred(word_list, model_name):
    """向单个微服务发送预测请求"""
    # 根据名字选择对应的配置列表
    url = model_config[model_name][-1]
    data = {"word_list": str(word_list)}
    res = requests.post(url=url, data=data)
    # 将该线程中获取的结果放到模型预测结果列表中
    model_prediction.append([model_name, eval(res.text)])
    return res.text




def request_model_serve(word_list, model_list):
    """该函数开启多线程请求封装好的模型微服务"""

    def _start_thread(pred, x, y):
        """开启预测线程, 以线程需要执行的函数和函数的输入为参数"""
        t = threading.Thread(target=pred, args=(x,y))
        t.start()
        return t

    # 遍历model_list, 调用开启线程函数_start_thread，会获得一个所有开启后的线程列表
    t_list = list(map(lambda model: _start_thread(pred, word_list, model), model_list))
    # 线程将逐一join操作等待所有线程完成
    t_list = list(map(lambda t: t.join(), t_list))
    # 最后过滤掉所有概率预测小于0.5的类别，返回结果
    result = list(filter(lambda x: x[1] >= 0.5, model_prediction))
    return result

```

> * 运行示例：

```python
word_list = ["我是", "美妆", "博主"]
model_list = ["美妆", "电影"]
result = request_model_serve(word_list, model_list)
```


```text
[['美妆', 0.9164116]]
```

* 当前步骤总结：
	* 通过以上函数我们使用多线程对模型子服务进行了请求，对收集到的结果进行的过滤处理，该函数也是我们任务一中主服务请求的一部分。




---

#### Step3: 系统联调与测试

* 当前步骤简述：
	* 这是文本标签化系统的最后一个步骤，我们将在这里回顾之前的一些核心环节，再次对系统整体的服务逻辑有一次深刻认识。


* 明确系统处理请求的五个环节:
	* 输入预处理
		* 对输入的文本做长度验证, 分词, 去停用词等处理操作.
	* 图谱匹配
		* 使用输入文本中的词汇进入到图谱中进行匹配, 找出所有可能的标签.
	* 匹配歧义判断
		* 使用模型对所有不确定的标签进行判断, 找出最合适的标签.
	* 概率调整
		* 调整标签的概率, 满足随着相关词汇增多, 概率逐渐增大
	* 概率归一化与父标签检索
		* 对概率进行归一化处理, 并检索匹配标签的父级标签列表.

* 代码实现位置：
	* 这些代码在步骤一已经有了一定的实现，这里进行回顾。
	* /data/labeled_project/text_labeled/views.py


#### 让我们动手做起来吧!

* 主服务逻辑代码实现：

```python
# Flask框架固定工具
from flask import Flask
from flask import request

app = Flask(__name__)


import json
import api

# 定义服务请求路径和方式, 这里使用POST请求
@app.route("/api/get_label/", methods=["POST"])
def recognition():
    # 接收POST请求，并取数据中的"text"对应的值
    text = request.form.get("text")
    # 调用输入预处理
    word_list = api.handle_cn_text(text)
    # 调用图谱匹配
    index_map_label = api.get_index_map_label(word_list)
    # 调用匹配歧义判断
    index_map_label_ = api.weight_update(word_list, index_map_label)
    if index_map_label_:
        # 调用概率调整
        df_ = api.control_increase(index_map_label_)
        # 调用概率归一化与父标签检索
        result = api.father_label_and_normalized(df_)
    else:
        result = []
    return str(result)
```

* 使用supervisor后台启动服务:

```shell
supervisord -c supervisord.conf
```

* 当前步骤总结：
	* 到这里，我们就完成文本标签化系统的一系列重点工作，关于启动了一个可用的标签化服务。


