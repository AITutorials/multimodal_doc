### 学习目标

* 了解什么是模型热更新以及如何做到热更新。
* 了解Flask框架及其相关的服务组件。
* 掌握使用Flask框架将模型封装成服务的流程。



---

### 什么是模型热更新

* 因为训练AI模型往往是较大的文件，在每次IO时往往比较耗时，因此会选择在服务开启时读入内存，避免IO操作。而这样的话，就意味着当我们更新模型时需要暂停服务， 这对于在线任务是非常不可取的行为；因此我们需要一种既能避免IO又能使用户无感知的方式，这种的要求就是模型热更新要求。


---

### 如何做到热更新

* 最常见的满足热更新要求的方法就是一同开启两个模型服务，一个作为正式使用，一个作为backup(备用)，当我们有更新需求时，将正式服务暂停进行模型更换，而此时备用服务将继续为用户服务，直到正式服务重新上线。在正式服务运转正常后，再为备用服务更换模型。


---


### Flask服务组件

![](./img/Flask.png)


* web框架FLask：
	* Flask框架是当下最受欢迎的python轻量级框架, 也是pytorch官网指定的部署框架. Flask的基本模式为在程序里将一个视图函数分配给一个URL，每当用户访问这个URL时，系统就会执行给该URL分配好的视图函数，获取函数的返回值.

<center>![](./img/Flask_1.png)</center>

---

* 作用:
	* 在项目中, Flask框架是主逻辑服务和句子相关模型服务使用的服务框架.

---

* 安装:

```shell
# 使用pip安装Flask
pip install Flask==1.1.1
```

---


* 基本使用方法:

```python
# 导入Flask类
from flask import Flask
# 创建一个该类的实例app, 参数为__name__, 这个参数是必需的，
# 这样Flask才能知道在哪里可找到模板和静态文件等东西.
app = Flask(__name__)

# 使用route()装饰器来告诉Flask触发函数的URL
@app.route('/')
def hello_world():
    """请求指定的url后，执行的主要逻辑函数"""
    # 在用户浏览器中显示信息:'Hello, World!'
    return 'Hello, World!'

if __name__ == '__main__':
    app.run(host="0.0.0.0", port=5001)
```


---


* 代码位置:
	* /data/ItcastBrain/Info/fasttext_server/app.py

---

* 启动服务:

```shell
python app.py
```


---

* 查看效果:
	* 通过浏览器打开地址http://0.0.0.0:5001可看见打印了'Hello, World'.


---


![](./img/gunicorn.png)


* web组件Gunicorn:
	* Gunicorn是一个被广泛使用的高性能的Python WSGI UNIX HTTP服务组件(WSGI: Web Server Gateway Interface)，移植自Ruby的独角兽（Unicorn ）项目，具有使用非常简单，轻量级的资源消耗，以及高性能等特点。


---


* 作用:
	* 在项目中, Gunicorn和Flask框架一同使用, 处理请求, 因其高性能的特点能够有效减少服务丢包率.


---

* 安装:

```shell
# 使用pip安装gunicorn
pip install gunicorn==20.0.4
```

---


* 基本使用方法:

```shell
# 注意：kill掉之前的5001端口服务，不再使用原生的启动方式
# 而是使用gunicorn启动Flask服务:
gunicorn -w 1 -b 0.0.0.0:5001 app:app
# -w 代表开启的进程数, 我们只开启一个进程
# -b 服务的IP地址和端口
# app:app 是指执行的主要对象位置, 在app.py中的app对象
```


---




### 使用Flask框架将模型封装成服务


我们可以将模型封装成服务的流程分为三步:

* 第一步: 编写app.py文件
* 第二步: 使用gunicorn启动服务
* 第三步: 编写test.py进行接口测试
* 第四步: 使用Nginx代理两个服务满足热更新

---


#### 第一步: 编写app.py文件，代码实现如下:

```python
# Flask框架固定工具
from flask import Flask
from flask import request

app = Flask(__name__)


# 导入fasttext
import fasttext
import jieba

# 最新的模型，大家根据自己之前训练的模型名字进行修改
model_name = "name_question_1591259822.bin"

# 最新模型的全路径
model_path = "/data/ItcastBrain/Info/fasttext_model/" + model_name

# 加载已训练的模型，注意: 这段加载语句不能写入下方的函数中，
# 否则将会每次请求都会重新加载
model = fasttext.load_model(model_path)


# 定义服务请求路径和方式, 这里使用POST请求
@app.route("/v1/is_name_question/", methods=["POST"])
def recogniition():
    """
    姓名问题识别函数
    它的输入咨询师所有的对话和索引列表,[[content, index], [content, index], ...]
    它的输出是姓名问题文本对应的index，如果没有则为-1
    """
    # 首先接受传过来的数据体，即咨询师所有的对话和索引列表
    text = request.get_json()["text"]
    # 设置默认result为-1
    result = -1
    # 遍历对话内容和索引
    for te, index in text:
        # 使用模型进行预测
        predicted = model.predict(" ".join(jieba.cut(te)))
        if predicted[0][0] == "__label__name":
            # 如果预测出的标签为"__label__name", 则证明出现姓名询问语句
            # 记录索引
            result = index
            # 停止循环，因为在对话中客服往往只询问一次学员姓名
            break
    # 返回字符串类型的结果（返回json或str形式都是可以的）
    return str(result)
```

---

> * 代码位置:
	* /data/ItcastBrain/Info/fasttext_server/app.py


---

#### 第二步: 使用gunicorn来启动服务

```shell
# 假如我们不再/data/ItcastBrain/Info/fasttext_server/路径下启动
# 则可以添加--chdir参数来指明app路径
gunicorn -w 1 -b 0.0.0.0:5001  --chdir /data/ItcastBrain/Info/fasttext_server/ app:app
```

---

> * 输出效果:

```text
[2020-06-04 17:04:11 +0800] [28276] [INFO] Starting gunicorn 20.0.4
[2020-06-04 17:04:11 +0800] [28276] [INFO] Listening at: http://0.0.0.0:5001 (28276)
[2020-06-04 17:04:11 +0800] [28276] [INFO] Using worker: sync
[2020-06-04 17:04:11 +0800] [28279] [INFO] Booting worker with pid: 28279
Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.
```

---

#### 第三步: 编写test.py进行接口测试

```python
import requests
import time

# 根据gunicorn开启的5001端口，app.py中的url路径
url = "http://0.0.0.0:5001/v1/is_name_question/"
# key为text，内容为咨询师所有对话内容和索引的列表
data = {
    "text": [
        ["你好，你是想了解哪个课程呢？", 0],
        ["还在么同学？", 0],
        ["你好", 1],
        ["您想了解哪个专业的学费呢", 1],
        ["专业不同，学时学费也不一样", 1],
        ["好的，方便QQ或者微信，邮箱接收吗？我这边发您", 3],
        ["您贵姓", 5],
    ]
}
# 多层嵌套必须使用json=data
# 超时时间为200
start = time.time()
res = requests.post(url, json=data, timeout=200)
end = time.time()
print(end - start)
print(res.text)
```

---


>  * 代码位置:
	* data/ItcastBrain/Info/fasttext_server/test.py


---


> * 输出效果:

```text
# 平均处理一个请求只需要3.5ms
0.003493785858154297

# 返回对应的索引
5
```

---


#### 第四步: 使用Nginx代理两个服务满足热更新

到这里说明我们模型服务能够正常工作，之后我们将启动两个同样的服务，分别使用5001和5002端口, 并将两个服务使用Nginx代理宜满足热更新。下面对nginx进行一些简单介绍，并对其中的配置进行说明。

---


* Nginx:
	* Nginx是一个高性能的HTTP和反向代理web服务器，也是工业界web服务最常使用的外层代理。

---

* 安装：

```shell
yum install nginx
```


---

* Nginx热更新部分配置说明:
	* 这些配置已经为大家写好，可以在/data/ItcastBrain/conf/nginx/nginx.conf中进行查看。

```
...

 # 以下是与热更新有关的配置
 # 这里代理两个端口的服务
 # 其中5002为backup，即当5001服务停止时被启用
 # 这里的prod要与下面proxy_pass中http://后的名称相同
 upstream prod {
        server 0.0.0.0:5001;
        server 0.0.0.0:5002 backup;
     }

 # nginx的外层服务使用8086端口
 server {
        listen       8086;
        server_name  0.0.0.0;
         location /static/ {
            alias /data/ItcastBrain/static/;
         }

        # 这里注意prod要与上面upstream后的名称相同
        location / {
            proxy_pass     http://prod;
            include      /data/ItcastBrain/conf/nginx/uwsgi_params;
            proxy_set_header X-Real-IP $remote_addr;

        }
    }

...

```

---

* Nginx的启动:

```shell

# 实际中我们并不会直接启动Nginx，而是在整体服务部署时使用supervisor进行启动和关闭
# 因此这里大家了解以下启动命令即可
# -c是指向配置文件
# -g "daemon off;"代表非后台运行
nginx -c /data/ItcastBrain/conf/nginx/nginx.conf -g "daemon off;"
```



---


### 小节总结


* 学习了什么是热更新与如何做到热更新
* 学习了Flask服务组件的使用
* 学习了将模型封装成服务的流程
	* 第一步: 编写app.py文件
	* 第二步: 使用gunicorn启动服务
	* 第三步: 编写test.py进行接口测试
	* 第四步: 使用Nginx代理两个服务满足热更新


