




### 任务简述


* 通过任务一我们完成了主服务的构建，获得了一个能够接受请求的API。在任务一这个过程当中我们其实做了很多假设，其中之一就是：假设我们拥有了一个“标签词汇图谱”，所以，在这个任务中，我们就是要搭建这个图谱，它是由标签体系和对应的关键词组成，同时是一个基于Neo4j的图存储，有了它，我们将预处理后的文本进行图谱匹配，可以获得一部分没有歧义的标签。


### 任务目的

* 根据业务制定的标签体系，构建起基于Neo4j的构建标签词汇图谱，以便完成图谱匹配。


### 任务步骤
	
* Step1: 设计标签树
* Step2: 构建标签树
* Step3: 获取原始数据
* Step4: 获取词汇集  
* Step5: 将词汇集导入图谱


---





#### Step1: 设计标签树

* 当前步骤简述：
	* 在企业里，每一个项目都会和业务挂钩，在我们的项目中，设计标签树就是和业务强关联的部分，我们将同业务人员一起设计产品的标签树，在设计过程当中，我们总结了一些设计原则。

* 业务导向原则：
	* 标签设计必须与公司业务强相关, 明确产品长期稳定需求, 尽量减少标签变动,这需要我们去了解自己公司的产品，不要一味去追求大而全.

* 最小可行化原则:
	* 搭建最小的用户可用和程序可实现的标签树，要记住我们的标签体系就像模型一样,是不断迭代的，所以初期设计要遵循最小可行化.


* 扁平化的存储原则:
	* 一般的标签树都会有一些嵌套的情况，在代码解析遍历过程中使其变得不可读，因此我们的最大允许嵌套是两层，这并不是说我们的标签树只能有两级，而是通过冗余的方式来控制嵌套层数。在下面给定的标签体系中你就会理解。

* 当前的一级标签：

```json
{
    "泛娱乐":[
        "明星",
        "美妆",
        "时尚",
        "影视",
        "音乐",
        "游戏",
        "美食"
    ]
}
```

* 当前的二级标签：

```json
{
    "游戏":[
        "LOL",
        "王者农药",
        "吃鸡"
    ],
    "影视":[
        "喜剧",
        "综艺",
        "科幻",
        "恐怖"
    ],
    "音乐":[
        "摇滚乐",
        "民谣",
        "Rap",
        "流行乐"
    ]
} 
```

* 注：以上标签同学们可以根据公司的情况进行自定义，即使是拥有三级标签，它也会将二级标签中的value作为三级中的key，保证嵌套只有两层。






#### 让我们动手做起来吧！

* 这一步我们要做的事情很简单，就是将这个标签结构持久化到文件中，这个结构命名为：LABEL_STRUCTURE

* 我们将这个结构作为配置，写在路径文件：
	* /data/labeled_project/text_labeled/settings.py


* 标签存储：

```json
LABEL_STRUCTURE = [
    {
        "泛娱乐":[
            "明星",
            "时尚",
            "游戏",
            "影视",
            "音乐",
            "美妆"
        ]
    },
    {
        "游戏":[
            "LOL",
            "王者农药",
            "吃鸡"
        ],
        "影视":[
            "喜剧",
            "综艺",
            "科幻",
            "恐怖"
        ],
        "音乐":[
            "摇滚乐",
            "民谣",
            "Rap",
            "流行乐"
        ]
    }
]
```


* 当前步骤总结：
	* 这一步并没有太多的程序的部分，更多是让大家了解一下业务设计上的一些原则，丰富项目的业务感。


---

#### Step2: 构建标签树


* 当前步骤简述：
	* 通过Step1我们已经构建了标签体系（也就是标签树），现在我们需要将它存储在图数据库当中，以便之后进行快速查询。



* 输入：
	* 标签体系LABEL_STRUCTURE

* 输出：
	* 在neo4j图数据当中显示该结构。



* 代码实现位置：
	* 不存在的路径需要自己的创建
	* /data/labeled_project/text_labeled/create_graph/build.py


#### 让我们动手做起来吧！


* 代码实现：

```python
from neo4j.v1 import GraphDatabase
from settings import NEO4J_CONFIG, LABEL_STRUCTURE


def create_label_node_and_rel():
    """该函数用于创建标签树的节点和边"""
    _driver = GraphDatabase.driver(**NEO4J_CONFIG)
    with _driver.session() as session:
        # 删除所有Label节点以及相关联的边
        cypher = "MATCH(a:Label) DETACH DELETE a"
        session.run(cypher)

        def _create_node_rel(l: dict):
            """根据标签树结构中的每一个字典去创建节点和关系"""
            if not l:
                return
            # 遍历字典中的k,v即父子标签
            for k, v in l.items():
                # MERGE一个父标签节点
                cypher = "MERGE(a:Label{title: %r})" % (k)
                session.run(cypher)

                def __c(word):
                    """用于创建子标签节点以及与父标签之间的关系"""
                    cypher = (
                        "CREATE(a:Label{title: %r}) \
                              SET a.name=%r WITH a \
                              MATCH(b: Label{title: %r}) \
                              MERGE(b)-[r:Contain]-(a)"
                        % (word, word, k)
                    )
                    session.run(cypher)

                # 遍历子标签列表
                list(map(__c, v))

        # 遍历标签树列表
        list(map(_create_node_rel, LABEL_STRUCTURE))
```


> * 运行示例：

```python
create_label_node_and_rel()
```


> * 图数据库输出效果：

![](http://121.199.45.168:8000/img/%E6%A0%87%E7%AD%BE%E6%A0%91.png)


* 当前步骤总结：
	* 通过函数create_label_node_and_rel()我们在neo4j中构建了我们之前设计的标签树。


---


#### Step3: 获取原始数据

* 当前步骤简述：
	* 我们这个任务的目标是构建“标签词汇图谱”，通过前两步我们已经有了标签的部分，现在还差词汇的部分，那词汇怎么来呢？首先我们要明确我们需要什么样的词汇，按照之前的项目理解，这些词汇应该多少和我们设定的标签具有一定的关系，因此，我们的原始数据就是和标签有关的文章，之后再通过一定的分词获得词汇，这一步我们就主要关注一下文章部分。

* 原始数据的来源：
	* 公司内部会提供一部分
	* 同时通过数据抓取技术进行一些网络文章的抓取


* 我们这里为同学们提供“明星”，“时尚”，“美妆”，“影视”四种类型的文章

> * 明星

```text
玩笑归玩笑，谈到录制感受和评选标准时，沈腾自爆自己是最心软的观察员，给的yes最多，“可能是年纪大了，特别容易被选手感染，之前一个歌手刚开口，我就忍不住想哭”。
相对而言，金星算是比较严格的梦想观察员，她心目中的“达人”要在自己的普通生活之外，有着与众不同且足够极致的长处，“我对每个节目有40秒的忍耐期，如果在这之后没有打动我的东西，我就会按no。”
作为团内最年轻的成员，活泼的杨幂表现出了鲜明的“团宠属性”。不仅亲切地称呼沈腾为“二舅”、金星为“金姨”，还和口中的“我哥”蔡国庆共享暗号。节目录制下来，杨幂谦虚表示，自己在《达人秀》的舞台上见识了很多震撼的表演，是一次长见识的旅程。至于评判标准，杨幂坦言，自己对于一些专业表演没有太多见解，主要尊崇内心做选择。
```


> * 时尚

```text
采访中她曾提到希望大家包容她善待她，不管是她饰演的角色还是她本人。她为角色发声，为校园霸凌发声，同样为自己发声，希望观众对于她这个新人演员，能在给予严格的要求同时更给予情感的包容。而面对一些diss和嘲讽她的言语，她也表示不会因此而改变，而是会选择坚持自我，不忘初心，做自己。她曾说过“人生本无意义，人的存在就是为了创造意义。”年龄虽小，却是个有主见有自我坚持的女孩。
坚定如初
上衣：Hollister
裤子：Hollister
鞋：Mizuno
耳环：Inch Edition
耳夹：Thing In Thing
青春少女持刀出行，刀韧锋利却不敌她眼中的坚定与炙热。让我们看到了一个不到20岁的少女超出常人的成熟，和年轻充满活力的小性感。
粉色套装：Isabel Marant
鞋子：Stuart Weitzman
耳环：Atelier Swarovski
```

> * 影视

```text
电影有无限的可能性，原声音乐也能给电影创作提供灵感，电影和音乐的关系是开放的。为发出这样的讯号，FIRST影展今年与MOO音乐携手合作，在电影节期间提供了一个电影和音乐交叉的场景。
MOO音乐隶属于腾讯音乐娱乐集团，创立以来受到不少深度音乐爱好者的青睐。以天然的曲库优势为依托，MOO音乐致力于融合先锋与经典，拓展当代流行音乐的边界，为用户提供纯粹的沉浸式音乐体验，致力于成为一个引领当代青年人发现、探索新鲜流行乐的新一代潮流音乐APP。
作为FIRST影展音乐平台合作伙伴，MOO音乐赞助了场外奖“先锋音乐突破奖”，这也是FIRST首次设立电影音乐方向的专项奖。为《春潮》配乐的音乐人半野喜弘获得了这一奖项，MOO音乐产品负责人王宝华为他颁奖，称赞“这是先锋的音乐”。
半野喜弘的作品经常出现在侯孝贤和贾樟柯导演的电影里，《戏梦人生》《海上花》《山河故人》中的配乐都体现了他成熟的音乐思维和对影像独立、立体的理解。《春潮》导演杨荔钠曾这样描述他们的创作过程：“他隔空对话，视频传送，反覆修改你的旋律，《春梦》《春潮》都留有他谱写的乐章。”《春潮》同时将在宣发阶段得到MOO和QQ音乐的推广资源，等待早日与观众见面。
```


> * 美妆

```text
怡丽丝尔优悦活颜眼唇抚纹精华霜睛采上市
9周淡纹,眼证为实，新一线女性生活真相代表papi酱带你一同见证
 2018年5月10日,怡丽丝尔于北京虞社演艺空间举办全新优悦活颜眼唇抚纹精华霜新品发布会.品牌总监上田典史先生亲临现场，更携手知名原创视频达人papi酱作为特邀真相见证人，揭晓《新一线女性生活真相》白皮书，盛邀来自全国各地的主流时尚美妆媒体、众多知名美妆博主及护肤达人共同加入“9周淡纹，眼证为实”的见证人行列中来。
首先映入眼帘的是一个数字“9”造型的通道,置身其中，一条条关于护肤的“真相”弹幕袭来：“中年少女选购护肤品有多挑剔”、“猜猜你的衰老临界点在几点”等问题让来宾会心一笑的同时，亦引发了护肤真相的诸多思考.怡丽丝尔始终致力于亚洲女性之美，本次联合中国领先的社会化商业资讯提供机构Kantar Media CIC，将多年来对中国女性的关注汇聚为一本独具见解与洞察力的《新一线女性生活真相》白皮书，通过大数据破解新一线女性的皱纹秘密，从社会热点、生活方式和护肤习惯三个方面唤起大家对皱纹的认知及重视。
怡丽丝尔品牌总监上田典史先生表示： “自2017年在中国开展品牌革新以来,怡丽丝尔从未停下脚步，不断向前.我们始终关注亚洲女性之美，致力于为消费者提供持续创新的产品和价值体验。在这样的品牌愿景下，怡丽丝尔将目光聚焦于当下中国新一线女性的生活。我们发现尽管大部分中国女性十分注重抗老化问题，但却普遍认为护肤产品效果不尽人意。为满足广大中国消费者对于抚纹的护肤诉求，此次全新推出了功效认证的怡丽丝尔优悦活颜眼唇抚纹精华霜，不仅是品牌价值的有力证明，更标志着怡丽丝尔又一次的创新与突破。我们期待这款产品让更多中国女性绽放自信与健康的光芒，成就积极向上与自信坚强的魅力人生，遇见更好的自己。 “
```

* 原始语料存放位置：
	* /data/labeled_project/text_labeled/create_graph/



* 原始语料的基本特性：
	* 文章一般优选短文,在几百至一千字左右，保证内容比较聚焦。
	* 内容涉猎很多相关领域关键词，利于之后的词汇提取。



* 当前步骤总结：
	* 在这个步骤中，我们没有需要开发的代码，更多是下载原始语料以及对这种文本有一定的认知，在面试中，这些原始文本的特性也可能是考察的重点。

---



#### Step4: 获取词汇集

* 当前步骤简述：
	* 上一步我们得到了很多的原始文本，但是我们的目标是构建“标签词汇图谱”，因此基于原始文本我们需要获得里面的一系列关键词，在企业里，你可能会使用内部的分词/词性标注服务，在这里我们使用jieba替代。 



* 获取关键词的方式：
	* 获取关键词的方式很多，tfidf，textrank，NER等等，这里根据我们的业务形式和实际文本情况，我们使用一种基于词性过滤的方法，也就是说，我们假定在原始文本中，具有名词词性的词汇是具有更高标签信息量的。（比如，我爱看霸王别姬，很明显，霸王别姬这个名词词汇是电影标签的主要判断来源）


* 技术要求：
	* 使用jieba的词性识别功能
	* 了解jieba中名词词性的代表方式



* 输入：
	* 某个标签下的原始文本段

* 输出：
	* 该标签下的一系列具有名词词性的词汇，并写入到对应标签名的csv文件之中
	* 如: 时尚.csv


* 代码实现位置：
	* /data/labeled_project/text_labeled/create_graph/get_vocab.py




#### 让我们动手做起来吧！

* 代码实现：

```python
import os
import jieba

# 使用jieba中的词性标注功能
import jieba.posseg as pseg

# jieba中预定义的名词性类型,分别表示: 人名，名词，地名，机构团体名，其他专有名词
n_e = ["nr", "n", "ns", "nt", "nz"]

# 写入csv的路径
csv_path = "./labels"

# 用户自定义词典路径
userdict_path = "../userdict.txt"

def get_vocabulary(article_path, csv_name):
    """函数将读取文章路径下的所有文章文本,并转化为词汇写入词汇csv文件"""
    if not os.path.exists(article_path): return
    if not os.path.exists(csv_path): os.mkdir(csv_path)
    def _get_n_list(text):
        """用于获取名词列表"""
        # 使用jieba的词性标注方法切分文本,获得具有词性属性flag和词汇属性word的对象, 
        # 从而判断flag是否在我们定义的名词性列表中,来返回对应的词汇
        r = []
        for g in pseg.lcut(text):
            if g.flag in n_e:
                r.append(g.word)
        return r

    with open(os.path.join(csv_path, csv_name), "a") as u:
        for article in os.listdir(article_path):
            with open(os.path.join(article_path, article), "r") as f:
                text = f.read()
            # 只获取长度大于等于2的名词
            n_list = list(filter(lambda x: len(x)>=2, set(_get_n_list(text))))
            list(map(lambda x: u.write(x + "\n"), n_list))

    with open(os.path.join(csv_path, csv_name), "r") as o:
        word = o.read()
        with open(userdict_path, "a") as f:
            f.write(word)
    return
```

> * 运行示例：

```python
# 原始文章路径
article_path = "./fashion"

# 生成的csv文件名字(该文件在./labels目录下)
csv_name = "时尚.csv"
```


```text
福利
心情
张扬
腰身
T恤
闲暇
增色
美颜
上海
全身
个人
造型
时刻
印象派
蓝色
靴子
```


* 当前步骤总结：
	* 通过get_vocabulary函数我们实现了关键词汇提取，同学们需要自己动手，将全部给定的四个标签下的原始语料都完成，并查看其中的词汇。





---

#### Step5: 将词汇集导入图谱

* 当前步骤简述：
	* 对应标签下的词汇我们已经准备好了，接下来就是将这些词汇导入到图谱当中，形成我们本次任务的目的：构建标签词汇图谱，这个实现过程和构建标签树类似，都是使用cypher进行图数据库的操作。


* 输入：
	* 已经完成在图谱中的标签树
	* 当前提取好关键词汇的csv文件


* 输出：
	* 在neo4j图数据当中显示标签词汇图谱。


* 代码实现位置：
	* /data/labeled_project/text_labeled/create_graph/build.py


#### 让我们动手做起来吧!

* 代码实现：

```python
import os
import random
import fileinput

csv_path = "./labels"

def create_vocabulary_node_and_rel():
    """该函数用于创建词汇节点和关系""" 
    _driver = GraphDatabase.driver(**NEO4J_CONFIG)
    with _driver.session() as session:
        # 删除所有词汇节点及其相关的边
        cypher = "MATCH(a:Vocabulary) DETACH DELETE a"
        session.run(cypher)

        def _create_v_and_r(csv):
            """读取单个csv文件,并写入数据库创建节点并与对应的标签建立关系"""
            path = os.path.join(csv_path, csv)
            # 使用fileinput的FileInput方法从持久化文件中读取数据,
            # 并进行strip()操作去掉两侧空白符, 再通过set来去重.
            word_list = list(
                set(map(lambda x: x.strip(), fileinput.FileInput(path))))

            def __create_node(word):
                """创建csv中单个词汇的节点和关系"""
                # 定义词汇的初始化权重,即词汇属于某个标签的初始概率，
                # 因为词汇本身来自该类型文章，因此初始概率定义在0.5-1之间的随机数
                weight = round(random.uniform(0.5, 1), 3)
                # 使用cypher语句创建词汇节点,然后匹配这个csv文件名字至后四位即类别名，
                # 在两者之间MERGE一条有权重的边
                cypher = "CREATE(a:Vocabulary{name:%r}) WITH a \
                          MATCH(b:Label{title:%r}) \
                          MERGE(a)-[r:Related{weight:%f}]-(b)" % (word, csv[:-4], weight)
                session.run(cypher)
            # 遍历词汇列表
            list(map(__create_node, word_list))
        # 遍历标签列表
        label_list = os.listdir(csv_path)
        list(map(_create_v_and_r, label_list))

```

> * 运行示例：

```python
# 词汇集csv文件路径
csv_path = "./labels"
create_vocabulary_node_and_rel()
```


> * 输出效果：

![](http://121.199.45.168:8000/img/%E8%AF%8D%E6%B1%87.png)

* 当前步骤总结：
	* 通过函数create_vocabulary_node_and_rel()我们完成了词汇集导入图谱，同时也终于构建起了我们需要的标签词汇图谱，在这个过程当中，增强了我们对neo4j的操作能力以及对业务问题的进一步理解，在之后的任务中，我们将开始将注意力集中在模型上。


---


